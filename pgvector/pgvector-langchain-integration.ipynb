{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa996aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "#from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "#from langchain.embeddings import openai\n",
    "#from langchain_openai import OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from pathlib import Path\n",
    "from configparser import ConfigParser\n",
    "\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import os\n",
    "#load_dotenv()\n",
    "BASE_DIR = os.getcwd() #Path(__file__).parents[1]\n",
    "DB_INIT_FILE = BASE_DIR +'/database.ini'\n",
    "\n",
    "\n",
    "def db_config(filename: Path = DB_INIT_FILE, section: str = 'postgresql'):\n",
    "    parser = ConfigParser()\n",
    "    parser.read(filename)\n",
    "    if parser.has_section(section):\n",
    "        params = parser.items(section)\n",
    "        db = {param[0]: param[1] for param in params}\n",
    "    else:\n",
    "        raise Exception(f'Section {section} not found in the {filename} file')\n",
    "    return db\n",
    "\n",
    "\n",
    "\n",
    "import psycopg2\n",
    "\n",
    "def create_db_connection():\n",
    "    params = db_config()\n",
    "    try:\n",
    "        conn = psycopg2.connect(**params)\n",
    "        return conn\n",
    "    except (Exception, psycopg2.Error) as error:\n",
    "        print(\"Error while connecting\", error)\n",
    "    return None\n",
    "\n",
    "\n",
    "import requests\n",
    "\n",
    "model_id = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "api_url = f\"https://api-inference.huggingface.co/pipeline/feature-extraction/{model_id}\"\n",
    "hf_token = os.getenv('HF_ACCESS_TOKEN')\n",
    "headers = {\"Authorization\": f\"Bearer {hf_token}\"}\n",
    "\n",
    "def QueryModelWithTextChunks(texts):\n",
    "    response = requests.post(api_url, headers=headers, json={\"inputs\": texts, \"options\":{\"wait_for_model\":True}})\n",
    "    return response.json()\n",
    "\n",
    "def SaveEmbeddings(embeddingDF, textsList):\n",
    "    connection = create_db_connection()\n",
    "    cursor = connection.cursor()\n",
    "    try:\n",
    "        for text, embedding in zip(textsList, embeddingDF):\n",
    "            cursor.execute(\n",
    "                \"INSERT INTO embeddings (embedding, text) VALUES (%s, %s)\",\n",
    "                (embedding, text)\n",
    "            )\n",
    "        connection.commit()\n",
    "    except (Exception, psycopg2.Error) as error:\n",
    "        print(\"Error while writing to DB\", error)\n",
    "    finally:\n",
    "        if cursor:\n",
    "            cursor.close()\n",
    "        if connection:\n",
    "            connection.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc999495",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "loader = TextLoader(\"lease-11-1958.txt\", encoding=\"utf-8\")\n",
    "raw_doc_list = loader.load()\n",
    "#print(len(docs))\n",
    "#text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=80)\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\\n\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "doc_chunk_list = text_splitter.split_documents(raw_doc_list)\n",
    "text_chunk_list = [c.page_content for c in doc_chunk_list]\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model_output_embeddings = QueryModelWithTextChunks(text_chunk_list)\n",
    "\n",
    "#import pandas as pd\n",
    "#embeddings = HuggingFaceEmbeddings()\n",
    "\n",
    "\n",
    "#embeddings = pd.DataFrame(output)\n",
    "#print(embeddings)\n",
    "\n",
    "'''\n",
    "ref: https://github.com/langchain-ai/langchain/issues/2219\n",
    "\n",
    "from langchain.vectorstores.pgvector import PGVector\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "import os\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "texts = TextLoader('data/made-up-story.txt').load()\n",
    "documents = CharacterTextSplitter(chunk_size=500, chunk_overlap=20).split_documents(texts)\n",
    "\n",
    "CONNECTION_STRING = PGVector.connection_string_from_db_params(\n",
    "    driver=os.environ.get(\"PGVECTOR_DRIVER\", \"psycopg2\"),\n",
    "    host=os.environ.get(\"PGVECTOR_HOST\", \"localhost\"),\n",
    "    port=int(os.environ.get(\"PGVECTOR_PORT\", \"5432\")),\n",
    "    database=os.environ.get(\"PGVECTOR_DATABASE\", \"postgres\"),\n",
    "    user=os.environ.get(\"PGVECTOR_USER\", \"postgres\"),\n",
    "    password=os.environ.get(\"PGVECTOR_PASSWORD\", \"postgres\"),\n",
    ")\n",
    "\n",
    "db = PGVector.from_documents(\n",
    "    embedding=embeddings,\n",
    "    documents=documents,\n",
    "    collection_name=\"test\",\n",
    "    connection_string=CONNECTION_STRING,\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10108b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores.pgvector import PGVector\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "model_id = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=model_id)\n",
    "#ADA_TOKEN_COUNT \n",
    "\n",
    "params = db_config()\n",
    "conStr = f\"postgresql+psycopg2://{params['user']}:{params['password']}@{params['host']}:{params['port']}/{params['database']}\"\n",
    "db1 = PGVector.from_documents(embedding=embeddings, \n",
    "                              documents=doc_chunk_list, \n",
    "                              collection_name=\"embeddings2\", \n",
    "                              connection_string=conStr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ccba85f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Document(page_content='10. Not the leave or park any motor or other vehicle in the carriageway\\nadjoiining the read of the Building so as to cause annoyance or in-\\nconvenience to the Lessor or any lessee or occupier of any flat in the\\nbuilding.\\n\\n11. Not to fix a wireless or telefision aerial to the exterior of the\\nsaid flat or building but shall be entitled to use such television\\naerial as the Lessor may erect on the roof of the said building, the\\nposition of such aerial to be at the absolute discretion of the\\nLessor.', metadata={'source': 'lease-11-1958.txt'}), 0.6952251377567562)\n",
      "(Document(page_content='PART II: [RIGHTS INCLUDED IN DEMISE]\\n\\t\\t\\t\\n1. The right in common with the Lessor and the Lessees or occupiers\\nfor the time being of the other Flats in the Building and all others\\nhaving the like right to use for purposes of access to and egress from\\nthe Flat first the service road and paths coloured yellow on the said \\nplan and second the entrance hall and saircase leading from the \\nground floor to the landing of the flat.\\n\\n2. The right in common with all others for the time being having the\\nlike right of passage and running of gas electricity water and soil\\nfrom and to the Flat through the pipes wires conduits and drains in \\nunder or upon the Building.\\n\\n3. All such rights of support and protection as are enjoyed by the\\nFlat from the other flats adjoining the same at the date hereof.', metadata={'source': 'lease-11-1958.txt'}), 0.777879148721695)\n",
      "(Document(page_content='3. All such rights of support and protection as are enjoyed by the\\nFlat from the other flats adjoining the same at the date hereof.\\n\\n4. The right to use in common with the Lessor and the lessees or\\noccupiers for th etime being of other flats in the building and their \\nvisitors the lawns and gardens coloured green on the Estate plan\\nsubject to such reasonable rules and regualtions for the common enjoy-\\nment thereof as the Lessor may from time to time prescribe.\\n\\n5. The right (to be exercised save in a case of urgency only at \\nreasonable times and upon being given reasonable notice) to enter upon\\nthe premises adjoining the Flat and in particular upon the flat known\\nas No 9 for the purpose only of executing any necessary repairs and\\nalterations to the demised premises the LEssee causing as little \\ndamage disturbance and inconcenience as possible and making good all\\ndamage occasioned tehreby but without making any compensation for any\\ntemporary damage or inconvenience.', metadata={'source': 'lease-11-1958.txt'}), 0.7845447469300318)\n",
      "(Document(page_content='NOW THIS LEASE made in consideration of the sum\\nof [Â£2550.00] TWO THOUSAND FIVE HUNDERED AND FIFTY POUNTDS paid by the Lessee to\\nthe Lessor (the receipt whereof the Lessor hereby achnowledges) and \\nof the yearly rent and covenants on the part of the Lessee hereinafter\\nreserved and contained WITNESSETH as follows:-\\n\\n1. The Lessor HEREBY DEMISES unto the Lessee ALL THAT Flat and landing described in Part I of the Schedule hereto (hereinafter\\ntogether called \"the Flat\") TOGETHER with the rights privileges and\\nappurtenances set out in Part II of the Schedule hereto EXCEPT AND \\nRESERVING to the Lessor the rights set out in Part III of the schedule \\nhereto\\n\\n\\tTO HOLD the same unto the Lessee from the [25.03.1957] twenty fifth day of\\nMarch One thousand nine hundred and fifty seven for the term of\\nNINETY NINE YEARS', metadata={'source': 'lease-11-1958.txt'}), 0.7850702957871812)\n"
     ]
    }
   ],
   "source": [
    "#similarQ1 = db1.similarity_search_with_score(\"rent for the ground\", k=2)\n",
    "similarQ1 = db1.similarity_search_with_score(\"parking\")#, k=2)\n",
    "\n",
    "for s in similarQ1:\n",
    "    print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31a567e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
